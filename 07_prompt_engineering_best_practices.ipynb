{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import openai\n",
        "# from openai import AzureOpenAI\n",
        "# import os \n",
        "# from azure.identity import ManagedIdentityCredential\n",
        "\n",
        "# default_credential=ManagedIdentityCredential(client_id=\"XXX\")\n",
        "# token=default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
        "# Resource_endpoint=\"XXX\"\n",
        "\n",
        "# client = AzureOpenAI(\n",
        "#   azure_endpoint = Resource_endpoint, \n",
        "#   api_key=token.token,  \n",
        "#   api_version=\"2023-05-15\"\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720097684406
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up Azure OpenAI\n",
        "load_dotenv(\"credentials.env\")\n",
        "\n",
        "openai.api_type = \"azure\"\n",
        "    \n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
        "    api_version=\"2024-02-01\",\n",
        "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761695805
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getenv(\"AZURE_OPENAI_ENDPOINT\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "https://swedencentral-shared-yk.openai.azure.com\n"
        }
      ],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761696112
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Understand the AOAI Models' capabilities. Start with the latest model, prove your idea , then test with smaller models. \n",
        "Model size is critical for better performance."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Be specific, descriptive and as detailed as possible about the desired context, outcome, length, format, style, etc"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Length ** control (specify desired output length e.g.: number of words)\n",
        "\n",
        "** Tone ** control (e.g.: polite, passionate, professional, technical, funny, casual, serious etc.)\n",
        "\n",
        "** Style ** control (e.g.: in the style of Shakespeare, JK Rowling, Nelson Mandela etc.)\n",
        "\n",
        "** Audience ** control (e.g.: a 5-year-old can understand etc)\n",
        "\n",
        "** Context ** control (e.g.: news, novel, textbook, report, white paper, blog etc.)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_system_message = \"You are a helpful assistant.\"\n",
        "system_message = f\"{base_system_message.strip()}\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = \" Write a 2 paragraph inspiring poem which can be understood by 5 years-old child focussing on pensions.\"\n",
        "# Write a 2 paragraph inspiring poem about Nationwide Building Society\n",
        "# Write a 2 paragraph inspiring poem focussing on products of Nationwide Building Society in a funny way\n",
        "# Write a 2 paragraph inspiring poem focussing on products of Nationwide Building Society in the style of Shakespeare"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761699882
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of appending, writing messages in the SDK\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "**The Future's Treasure Chest**  \n\nThink of a box, shiny and bright,  \nWaiting for you in the soft golden light.  \nEach coin you save, each little spare,  \nIs like planting seeds with loving care.  \nOne day you’ll open that magical case,  \nWith gifts and comforts in its special space.  \n\nA pension’s a hug from your future you,  \nSaying, \"I’m safe, thanks to all you do!\"  \nSo as the days and years go by,  \nKeep adding pennies, let your dreams fly high.  \nFor when you’re older, you’ll find with delight,  \nThe treasure you built feels just so right!  \n"
        }
      ],
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761704892
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Put instructions at the begining of the prompt and use ### or \"\"\" to separate the instruction and context"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Articulate the desired output format through examples"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\""
      ],
      "outputs": [],
      "execution_count": 46,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761705055
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_message=f\"\"\"Extract the entities mentioned in the text below. \n",
        "First extract all company names, then extract all years, \n",
        "then extract specific topics which fit the content and finally extract general overarching themes\\n\\n \n",
        "Desired format: \n",
        "Company names: <comma_separated_list_of_company_names> \n",
        "Years: \n",
        "Specific topics:\n",
        "General themes: \n",
        "### Text:\n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \n",
        "increasingly safe, useful, and powerful. \\n\\n \n",
        "###\n",
        "\"\"\"\n"
      ],
      "outputs": [],
      "execution_count": 47,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761705734
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of appending, writing messages in the SDK\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Company names: OpenAI, Microsoft  \nYears: 2019, 2021  \nSpecific topics: partnership extension, investment, independent research, artificial intelligence (AI), safety, usefulness, technological development  \nGeneral themes: innovation, collaboration, technology advancement, artificial intelligence, corporate investment  \n"
        }
      ],
      "execution_count": 48,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761708788
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Start with zero-shot, then few-shot (example)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\""
      ],
      "outputs": [],
      "execution_count": 49,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761709073
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_zero=f\"\"\"Extract most important keywords from the corresponding texts below.\\n\\n \n",
        "\n",
        "###Text: \n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \n",
        "increasingly safe, useful, and powerful. \\n\n",
        "Keywords:###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 50,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761710102
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_zero}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "OpenAI, Microsoft, partnership, multi-year, multi-billion dollar investment, independent research, AI, safe, useful, powerful.\n"
        }
      ],
      "execution_count": 51,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761712209
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_few=f\"\"\"Extract most important keywords from the corresponding texts below.\\n\\n \n",
        "### Text 1: \n",
        "Stripe provides APIs that web developers can use to integrate \n",
        "payment processing into their websites and mobile applications. \\n\n",
        "Keywords 1: Stripe, payment processing, APIs, web developers, websites \n",
        "### \n",
        "\n",
        "###Text 2: \n",
        "OpenAI has trained cutting-edge language models that are very good at understanding \n",
        "and generating text. Our API provides access to these models and can be used to solve virtually \n",
        "any task that involves processing language. \\n\n",
        "Keywords 2: OpenAI, language models, text processing, API.\n",
        "### \n",
        "\n",
        "###Text 3: \n",
        "We’re happy to announce that OpenAI and Microsoft are extending our partnership.\n",
        "This multi-year, multi-billion dollar investment from Microsoft follows their previous investments \n",
        "in 2019 and 2021, and will allow us to continue our independent research and develop AI that is \n",
        "increasingly safe, useful, and powerful. \\n\n",
        "Keywords 3:\"\"\""
      ],
      "outputs": [],
      "execution_count": 52,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761712445
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of appending, writing messages in the SDK\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_few}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "OpenAI, Microsoft, partnership, investment, AI research, safe AI, useful AI, powerful AI.\n"
        }
      ],
      "execution_count": 53,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761714817
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Instead of just saying what not to do, say what to do instead"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message= f\"\"\"You are an agent trying to diagnose the problem and suggest a solution, whilst refraining from asking any questions related to PII. \n",
        "Instead of asking for PII, such as username or password, refer the user to the help article www.samplewebsite.com/help/faq \\n\\n\"\"\"\n",
        "\n",
        "# This is the first user message that will be sent to the model. Feel free to update this.\n",
        "user_message = \"I can’t log in to my account.\"\n",
        "\n",
        "# Create the list of messages. role can be either \"user\" or \"assistant\" \n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": system_message},\n",
        "    {\"role\": \"user\", \"name\":\"example_user\", \"content\": user_message}\n",
        "]"
      ],
      "outputs": [],
      "execution_count": 54,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761714981
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "If you're having trouble logging into your account, it could be due to a few common issues. Here are some steps you can take to troubleshoot the problem:\n\n1. **Double-Check Your Credentials:** Make sure you're entering your email address (or username) and password correctly. Pay attention to caps lock and ensure there are no accidental spaces.\n\n2. **Reset Your Password:** If you've forgotten your password, use the \"Forgot Password\" option on the login page. You'll receive a password reset link at your registered email address. Follow the instructions to set a new password.\n\n3. **Browser Issues:** Clear your browser cache and cookies, then try logging in again. Alternatively, you can try logging in using a different browser or device.\n\n4. **Account Locked:** If you've made multiple failed login attempts, your account might be temporarily locked for security reasons. Wait for a while and try again.\n\n5. **Check Internet Connection:** Ensure your internet connection is stable and working properly.\n\n6. **Verify Email Address:** Make sure the email address linked to your account is active and accessible, as you may need it for receiving important login-related emails.\n\nIf you’ve tried these troubleshooting steps and still can't log in, I recommend visiting the help article at [www.samplewebsite.com/help/faq](www.samplewebsite.com/help/faq) for further assistance specific to your situation. \n"
        }
      ],
      "execution_count": 55,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761723232
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Divide complex tasks into sub-tasks"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\""
      ],
      "outputs": [],
      "execution_count": 56,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761723411
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "As an FSI company, we want our pension schemes to have a positive impact on our customers. Whether you're just starting to save into a pension or ready to take money out of it, we have the best interests of our members and customers at heart. It's about long-term financial wellbeing and sharing responsibility for building a better future. Save today to enjoy tomorrow.\"\"\"\n",
        "# example 1\n",
        "user_message = f\"\"\"\n",
        "Perform the actions below by separating your answers with line breaks. \n",
        "1 - Summarize the following text below with 1 sentence in English.\n",
        "2 - Translate the summary into Turkish.\n",
        "3 - List each company name in the Turkish summary.\n",
        "4 - Output a json object that contains the following:\n",
        "keys: turkish_summary, turkish_company_names.\n",
        "\n",
        "###\n",
        "Text:\n",
        "{text} \n",
        "###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761723689
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1 - The text highlights the commitment of an FSI company to providing pension schemes that positively impact customers and ensure their long-term financial wellbeing.  \n2 - Metin, bir FSI şirketinin müşteriler üzerinde olumlu bir etki yaratan ve uzun vadeli finansal refahı sağlayan emeklilik planları sunma taahhüdünü vurgulamaktadır.  \n3 - FSI  \n4 -  \n```json\n{\n  \"turkish_summary\": \"Metin, bir FSI şirketinin müşteriler üzerinde olumlu bir etki yaratan ve uzun vadeli finansal refahı sağlayan emeklilik planları sunma taahhüdünü vurgulamaktadır.\",\n  \"turkish_company_names\": [\"FSI\"]\n}\n```  \n"
        }
      ],
      "execution_count": 58,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761728674
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Chain of Thought"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The language model is prompted to generate a few intermediate reasoning steps to arrive at the final answer. \n",
        "\n",
        "Uses \"greedy decoding\" which means selecting the most likely token (word or character) at each step of the sequence generation process. At each time step, the model predicts the next token based on the previously generated tokens, and the token with the highest predicted probability is chosen as the output for that step. This process is repeated until the desired sequence length is reached or until a special end-of-sequence token is generated.\n",
        "\n",
        "**Temp=0** is used because it uses greedy decoding. It first creates the greedy coding and then the answer."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This prompt gets wrong answer\n",
        "\n",
        "PROMPT_ZERO_SHOT = \"\"\"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A: The answer (arabic numerals) is\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 59,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761728856
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": PROMPT_ZERO_SHOT}\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=200,\n",
        "    stop=[\"\\nQ:\"]\n",
        ")\n",
        "\n",
        "# Print the result\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Roger initially has 5 tennis balls. He buys 2 cans, each containing 3 tennis balls, so he gets \\( 2 \\times 3 = 6 \\) tennis balls from the cans. Adding these to the 5 he already has, Roger now has \\( 5 + 6 = 11 \\) tennis balls. He then gives 4 tennis balls to his friend, leaving him with \\( 11 - 4 = 7 \\) tennis balls.\n\nThe answer is **7**.\n"
        }
      ],
      "execution_count": 60,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761804975
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_ZERO_SHOT_CoT = \"\"\"Q:Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A: Let’s think step by step.\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 62,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761871923
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": PROMPT_ZERO_SHOT_CoT}\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=300,\n",
        "    stop=[\"\\nQ:\"]\n",
        ")\n",
        "\n",
        "# Print the result\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Sure! Let's break it down step by step:\n\n1. **Roger starts with 5 tennis balls.**\n   - Initial count: 5 tennis balls.\n\n2. **He buys 2 more cans of tennis balls. Each can has 3 tennis balls.**\n   - Total tennis balls in the cans: \\( 2 \\times 3 = 6 \\) tennis balls.\n   - Adding these to his initial count: \\( 5 + 6 = 11 \\) tennis balls.\n\n3. **He gives 4 tennis balls to his friend.**\n   - Subtracting the 4 tennis balls he gave away: \\( 11 - 4 = 7 \\) tennis balls.\n\n**Final Answer: Roger has 7 tennis balls now.**\n"
        }
      ],
      "execution_count": 63,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761876720
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_fsi_zeroshot_cot= \"\"\"Q: Let’s analyze the financial health of Company X. The company has a revenue of $10 million, expenses of $7 million, and a debt of $2 million. Calculate the net profit and the debt-to-equity ratio.\n",
        "A: The answer is\"\"\""
      ],
      "outputs": [],
      "execution_count": 65,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761910031
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_fsi_zeroshot_cot}\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    stop=[\"\\nQ:\"]\n",
        ")\n",
        "\n",
        "# Print the result\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "To analyze the financial health of Company X, let's calculate the **net profit** and the **debt-to-equity ratio** step by step.\n\n---\n\n### 1. **Net Profit**\nNet profit is calculated as:\n\n\\[\n\\text{Net Profit} = \\text{Revenue} - \\text{Expenses}\n\\]\n\nGiven:\n- Revenue = $10 million\n- Expenses = $7 million\n\n\\[\n\\text{Net Profit} = 10 - 7 = 3\n"
        }
      ],
      "execution_count": 66,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761913688
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_fsi_zeroshot_cot= \"\"\"Q: Let’s analyze the financial health of Company X. The company has a revenue of $10 million, expenses of $7 million, and a debt of $2 million. Calculate the net profit and the debt-to-equity ratio.\n",
        "A: Let's think step by step.\"\"\""
      ],
      "outputs": [],
      "execution_count": 69,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761959838
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_fsi_zeroshot_cot}\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    stop=[\"\\nQ:\"]\n",
        ")\n",
        "\n",
        "# Print the result\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Sure! Let's break this down step by step:\n\n### Step 1: Calculate the Net Profit\nNet profit is calculated as:\n\n\\[\n\\text{Net Profit} = \\text{Revenue} - \\text{Expenses}\n\\]\n\nGiven:\n- Revenue = $10 million\n- Expenses = $7 million\n\n\\[\n\\text{Net Profit} = 10 - 7 = 3 \\, \\text{million}\n\\]\n\nSo, the **Net Profit** is **$\n"
        }
      ],
      "execution_count": 70,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761968778
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_FEW_SHOT_CoT = \"\"\"\n",
        "Q: Elif went to market with £10 and consumed £2. How much does she have now?\n",
        "A: Elif had £10 at the beginning. When she consumed £2, 10-2=8 , £8 remains.\n",
        "Q:Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A:\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 72,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761984939
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": PROMPT_FEW_SHOT_CoT}\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=1000,\n",
        "    stop=[\"\\nQ:\"]\n",
        ")\n",
        "\n",
        "# Print the result\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Let's break it down step by step:\n\n1. **Roger starts with 5 tennis balls.**\n   - Initial count: 5 tennis balls.\n\n2. **He buys 2 cans of tennis balls, and each can has 3 tennis balls.**\n   - Total tennis balls in the cans: \\( 2 \\times 3 = 6 \\).\n   - New total: \\( 5 + 6 = 11 \\) tennis balls.\n\n3. **He gives 4 tennis balls to his friend.**\n   - Remaining tennis balls: \\( 11 - 4 = 7 \\).\n\n**Final Answer:** Roger has **7 tennis balls** now.\n"
        }
      ],
      "execution_count": 73,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749761993805
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Auto-COT ** uses zero-shot-cot results just like few-shot learning for reasoning. Instead of using few-shot-cot, auto-cot can be useful and easy because you don't need to create manual examples (labels/reasonings)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_auto_cot = \"\"\"\n",
        "Q:Roger has 5 tennis balls. He buys 2 more cans of tennis\n",
        "balls. Each can has 3 tennis balls. He gives 4 of them to his friend. How many tennis balls does\n",
        "he have now?\n",
        "A: Lets think step by step.Roger had 5 tennis balls at the beginning. He bought 2 cans of tennis balls, each with 3 balls, so he now has 5+2x3=11 tennis balls. After giving 4 to his friend, he has 11-4=7 tennis balls remaining.\n",
        "Q: Elif went to market with £10 and consumed £2. How much does she have now?\n",
        "A:\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 75,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762012145
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt_auto_cot}\n",
        "    ],\n",
        "    temperature=0.5,\n",
        "    max_tokens=1000\n",
        ")\n",
        "\n",
        "# Access the message content safely\n",
        "message_content = response.choices[0].message.content\n",
        "if message_content:\n",
        "    print(message_content.strip())\n",
        "else:\n",
        "    print(\"The response content is empty.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "The response content is empty.\n"
        }
      ],
      "execution_count": 76,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762018747
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Self Consistency\n",
        "\n",
        "Self-consistency aims \"to replace the naive greedy decoding used in chain-of-thought prompting\". The idea is to sample multiple, diverse reasoning paths through few-shot CoT, and use the generations to ** select the most consistent answer.**\n",
        "\n",
        "In the chat scenarios, **Asking the model to self-verify** its own responses. Like a student double-checking their answers, the AI model cross-references its responses to maintain consistency. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt= f\"\"\"When I was 6, my sister was half my age. Now\n",
        "I am 70 how old is my sister?\"\"\""
      ],
      "outputs": [],
      "execution_count": 77,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762041204
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    temperature=0.5,\n",
        "    max_tokens=230,\n",
        "    stop=[\"\\nA:\"]\n",
        ")\n",
        "\n",
        "# Print the result\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Let's figure this out step by step:\n\n1. When you were 6, your sister was **half your age**, which means she was:\n   \\[\n   6 \\div 2 = 3 \\text{ years old.}\n   \\]\n\n2. The age difference between you and your sister is:\n   \\[\n   6 - 3 = 3 \\text{ years.}\n   \\]\n\n3. Now that you are 70, your sister is still 3 years younger than you. So, her age is:\n   \\[\n   70 - 3 = 67 \\text{ years old.}\n   \\]\n\n**Answer: Your sister is 67 years old.**\n"
        }
      ],
      "execution_count": 78,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762045897
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2= f\"\"\"When I was 6, my sister was half my age. Now\n",
        "I am 70 how old is my sister? Let's think step by step\"\"\""
      ],
      "outputs": [],
      "execution_count": 79,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762059804
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",  # Ensure this is the correct model identifier\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt2}\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=1000\n",
        ")\n",
        "\n",
        "# Print the result\n",
        "print(response.choices[0].message.content.strip())\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Let's break this down step by step:\n\n1. **When you were 6, your sister was half your age.**\n   - If you were 6, and your sister was half your age, she must have been **6 ÷ 2 = 3 years old**.\n   - This means your sister is **3 years younger than you**.\n\n2. **Now you are 70 years old.**\n   - Since your sister is 3 years younger than you, we subtract 3 from your age:\n     \\[\n     70 - 3 = 67\n     \\]\n\n3. **Conclusion:**\n   - Your sister is **67 years old**.\n"
        }
      ],
      "execution_count": 80,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762080764
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt3=f\"\"\"\n",
        "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,\n",
        "there will be 21 trees. How many trees did the grove workers plant today?\n",
        "A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.\n",
        "So, they must have planted 21 - 15 = 6 trees. The answer is 6.\n",
        "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
        "A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\n",
        "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
        "A: Leah had 32 chocolates and Leah’s sister had 42. That means there were originally 32 + 42 = 74\n",
        "chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\n",
        "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops\n",
        "did Jason give to Denny?\n",
        "A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\n",
        "lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\n",
        "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does\n",
        "he have now?\n",
        "A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so\n",
        "in total he has 7 + 2 = 9 toys. The answer is 9.\n",
        "Q: There were nine computers in the server room. Five more computers were installed each day, from\n",
        "monday to thursday. How many computers are now in the server room?\n",
        "A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 =\n",
        "20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers.\n",
        "The answer is 29.\n",
        "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many\n",
        "golf balls did he have at the end of wednesday?\n",
        "A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On\n",
        "Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\n",
        "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
        "A: She bought 5 bagels for $3 each. This means she spent 5\n",
        "Q: When I was 6 my sister was half my age. Now I’m 70 how old is my sister?\n",
        "A:\"\"\""
      ],
      "outputs": [],
      "execution_count": 53,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1724222112505
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "def call_openai(num_times, start_phrase, temperature):\n",
        "    # Initialize the OpenAI client\n",
        "    #client = OpenAI(api_key='your-api-key')  # Replace with your actual API key\n",
        "\n",
        "    for i in range(num_times):\n",
        "        # Define the messages for the chat completion\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": start_phrase}\n",
        "        ]\n",
        "\n",
        "        # Send a chat completion request\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",  # Use the appropriate model name\n",
        "            messages=messages,\n",
        "            temperature=temperature,\n",
        "            max_tokens=100\n",
        "        )\n",
        "\n",
        "        # Extract and print the assistant's reply\n",
        "        reply = response.choices[0].message.content.strip()\n",
        "        print(f\"Response {i + 1}:\\n{reply}\")\n",
        "        print(\"*****************************\")\n"
      ],
      "outputs": [],
      "execution_count": 81,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762103227
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "call_openai(10, prompt3, temperature = 1)"
      ],
      "outputs": [],
      "execution_count": 82,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762104003
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Step-Back Prompting Technique"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You start by providing the model with a prompt or question.\n",
        "The model generates a response based on the initial prompt.\n",
        "Instead of immediately accepting the response, you prompt the model to review or analyse its own response. This could involve asking the model to check for errors, verify facts, or consider alternative approaches.\n",
        "Based on the reassessment, the model generates a refined or corrected response."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to generate a response based on a prompt  \n",
        "def generate_response(prompt):  \n",
        "    messages = [  \n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  \n",
        "        {\"role\": \"user\", \"content\": prompt}  \n",
        "    ]  \n",
        "    response = client.chat.completions.create(  \n",
        "        model=\"gpt-4o\",  \n",
        "        messages=messages  \n",
        "    )  \n",
        "    return response.choices[0].message.content.strip()  \n",
        "\n",
        "# function to rephrase the input text  \n",
        "def rephrase_input(input_text):  \n",
        "    rephrase_prompt = (  \n",
        "        \"You are a helpful assistant. Please rephrase the following request to make it clearer and a more general question: \"  \n",
        "        f\"'{input_text}'\"  \n",
        "    )  \n",
        "    messages = [  \n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  \n",
        "        {\"role\": \"user\", \"content\": rephrase_prompt}  \n",
        "    ]  \n",
        "    response = client.chat.completions.create(  \n",
        "        model=\"gpt-4o\",  \n",
        "        messages=messages  \n",
        "    )  \n",
        "    return response.choices[0].message.content.strip()  \n",
        "  \n",
        "  \n",
        "# function to reword and check the answer  \n",
        "def reword_and_check_answer(original_answer):  \n",
        "    rewording_prompt = f\"Reword and verify the following statement: '{original_answer}'\"  \n",
        "    messages = [  \n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  \n",
        "        {\"role\": \"user\", \"content\": rewording_prompt}  \n",
        "    ]  \n",
        "    response = client.chat.completions.create(  \n",
        "        model=\"gpt-4o\",  \n",
        "        messages=messages  \n",
        "    )  \n",
        "    return response.choices[0].message.content.strip()"
      ],
      "outputs": [],
      "execution_count": 83,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762128804
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_prompt = \"Nationwide is the largest bank in the UK.\"#\"I am a customer of Nationwide and plan to get a morgage soon. Does it have the lowest interest rate?\"  \n",
        "  \n",
        "# Generate a response based on the initial prompt  \n",
        "response = generate_response(initial_prompt)  \n",
        "print(\"*** Initial Response:\\n\", response)  \n",
        "  \n",
        "# Reword and verify the answer  \n",
        "checked_response = reword_and_check_answer(response)  \n",
        "print(\"*** Reworded and Checked Answer:\\n\", checked_response)  \n",
        "  \n",
        "print(\"*** Final Response:\\n\", checked_response)  \n",
        "  \n",
        "# if __name__ == \"__main__\":  \n",
        "#     initial_prompt = input(\"Enter your question: \")  \n",
        "#     response = generate_response(initial_prompt)  \n",
        "#     print(\"Initial Response:\\n\", response)  \n",
        "#     checked_response = reword_and_check_answer(response)  \n",
        "#     print(\"Reworded and Checked Answer:\\n\", checked_response)  "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "*** Initial Response:\n Actually, **Nationwide** is not a bank but a **building society**, and it is the largest building society in the UK—and, in fact, the world. While it provides many services similar to traditional banks, such as savings accounts, mortgages, and personal loans, its structure is different. Nationwide operates as a **mutual organization**, meaning it is owned by its members (customers) rather than external shareholders.\n\nIn terms of size, Nationwide competes with some of the largest financial institutions in the UK, but it is not larger than the UK's major banks, such as **HSBC**, **Barclays**, **Lloyds Banking Group**, or **NatWest Group**, which dominate the banking sector in scale.\n*** Reworded and Checked Answer:\n Here’s a reworded and verified version of the statement:\n\n\"Nationwide is not a bank but a **building society**, and it holds the distinction of being the largest building society in both the UK and the world. While it offers many of the same financial services as traditional banks—such as savings accounts, mortgages, and personal loans—its structure sets it apart. Nationwide operates as a **mutual organization**, meaning that it is owned by its members (i.e., its customers) rather than external shareholders.\n\nAlthough Nationwide is one of the largest financial institutions in the UK and competes with major players, it is not as large as the country's leading banks, such as **HSBC**, **Barclays**, **Lloyds Banking Group**, and **NatWest Group**, which dominate the sector in terms of overall size and scale.\"\n\n**Verification**:  \n- **Nationwide building society’s status**: It is indeed the largest building society in both the UK and the world, and it operates as a mutual organization.  \n- **Services offered**: Nationwide provides services like savings, mortgages, and personal loans, which are comparable to those offered by banks.  \n- **Size comparison**: While Nationwide is significant in scale among financial institutions, it is smaller than the UK's major banks, such as HSBC, Barclays, Lloyds Banking Group, and NatWest Group, which have a larger global and domestic presence.  \n\nThe statement as rephrased is accurate.\n*** Final Response:\n Here’s a reworded and verified version of the statement:\n\n\"Nationwide is not a bank but a **building society**, and it holds the distinction of being the largest building society in both the UK and the world. While it offers many of the same financial services as traditional banks—such as savings accounts, mortgages, and personal loans—its structure sets it apart. Nationwide operates as a **mutual organization**, meaning that it is owned by its members (i.e., its customers) rather than external shareholders.\n\nAlthough Nationwide is one of the largest financial institutions in the UK and competes with major players, it is not as large as the country's leading banks, such as **HSBC**, **Barclays**, **Lloyds Banking Group**, and **NatWest Group**, which dominate the sector in terms of overall size and scale.\"\n\n**Verification**:  \n- **Nationwide building society’s status**: It is indeed the largest building society in both the UK and the world, and it operates as a mutual organization.  \n- **Services offered**: Nationwide provides services like savings, mortgages, and personal loans, which are comparable to those offered by banks.  \n- **Size comparison**: While Nationwide is significant in scale among financial institutions, it is smaller than the UK's major banks, such as HSBC, Barclays, Lloyds Banking Group, and NatWest Group, which have a larger global and domestic presence.  \n\nThe statement as rephrased is accurate.\n"
        }
      ],
      "execution_count": 84,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762152076
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Iterative approach\n",
        "\n",
        "Prompt engineering is an iterative process. If you're unsatisfied with the AI's response, refine your prompt and try again. Analyze the results you receive and consider adjusting your prompt's context, clarity, or structure. This process of trial and error will help you better understand how the AI model interprets your prompts and allow you to fine-tune your approach.\n",
        "\n",
        "·        Try different prompts to find what works best\n",
        "\n",
        "·        When attempting few-shot learning, try also to include direct instructions\n",
        "\n",
        "·        Rephrase a direct instruction set to be more or less concise, e.g.: taking a previous example and giving the next instruction without having to repeat the input\n",
        "\n",
        "·        Try different personas keywords to see how it affects the response style\n",
        "\n",
        "·        Use fewer or more examples in the few-shot learning\n",
        "\n",
        "·        Co-create with AI: An example of a very useful prompt to get a good output from the LLM :"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=f\"\"\"\n",
        "Overall Results\n",
        "Year Ended December 31, 2023 versus 2022:\n",
        "Net income attributable to  ordinary shareholders was $1.1 billion for the year ended December 31, 2023, \n",
        "which compares to a net loss of $906 million from 2022, as a result of:\n",
        "• Favorable total investment returns recognized in net income of $1.1 billion for the year ended December 31, \n",
        "2023, consisting of the aggregate of net investment income, net realized (losses) gains, net unrealized gains \n",
        "(losses) and income (losses) from equity method investments, in comparison to negative total investment \n",
        "returns included in net income of $1.2 billion for the year ended December 31, 2022. The variance in total \n",
        "investment returns recognized in net income was driven by: \n",
        "◦ Net unrealized gains on our other investments, including equities of $397 million, in comparison to net \n",
        "unrealized losses in 2022 of $433 million, as a result of strong global equity market performance, \n",
        "particularly in the first and fourth quarters of 2023, and tightening high yield credit spreads, in comparison to \n",
        "the challenging market environment for the year ended December 31, 2022;\n",
        "◦ Net realized and unrealized gains on our fixed maturities of $66 million in 2023, compared to net realized \n",
        "and unrealized losses of $1.2 billion in 2022, primarily due to a decrease in interest rates across U.S., U.K. \n",
        "and European markets in 2023 as compared to significant increases in interest rates in 2022; \n",
        "◦ An increase in net investment income of $192 million in 2023 when compared to 2022, consistent with the \n",
        "increasing investment income we have earned on a sequential quarterly basis, primarily due to the \n",
        "reinvestment of fixed maturities at higher yields, deployment of consideration received from LPT and \n",
        "insurance transactions closed over the past 12 months and the impact of rising interest rates on our fixed \n",
        "maturities securities that are subject to floating interest rates; and\n",
        "◦ Income from equity method investments of $13 million, driven by income from our investments in Core \n",
        "Specialty and Citco, partially offset by losses from our investment in Monument Re, compared to losses of \n",
        "$74 million in 2022, primarily driven by losses from our investment in Monument Re. \n",
        "• An increase in other income of $241 million in 2023 when compared to 2022, largely driven by the first quarter \n",
        "2023 net gain recognized from the novation of the Enhanzed Re reinsurance of a closed block of life annuity \n",
        "policies; and \n",
        "• A favorable change in income tax benefit of $238 million, primarily driven by the establishment of a $205 million \n",
        "net deferred tax asset related to the enactment of the Bermuda Corporate Income Tax in December 2023. We \n",
        "also recorded a $25 million partial release of our deferred tax asset valuation allowance as a result of increases \n",
        "in projected taxable income in the U.S. and a reduction in deferred tax assets associated with decreases in \n",
        "unrealized losses on investment securities reported in AOCI in the U.S. and U.K. jurisdictions. This was partially \n",
        "offset by an increase in the valuation allowance in our U.K. and EU jurisdictions primarily due to losses, \n",
        "whereby no corresponding tax benefits were recognized for the period. \n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 85,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762152346
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative= f\"\"\" Your task is to explain given information in a very simple way.\n",
        "### Context:\n",
        "{text}\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 86,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762152703
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "In 2023, the company made a profit of $1.1 billion for its shareholders, which is a big improvement compared to losing $906 million in 2022. Here's what helped:\n\n1. **Better Investments:**\n   - They earned $1.1 billion from all investments in 2023, compared to losing $1.2 billion in 2022. The improvement was due to:\n     - Strong stock markets, especially in early and late 2023, generating $397 million in unrealized gains (compared to a $433 million loss in 2022).\n     - Gains of $66 million from bonds, helped by lower interest rates, compared to a $1.2 billion loss in 2022.\n     - An additional $192 million from regular investment income (e.g., earnings on bonds), due to better yields, higher reinvestments, and rising interest rates.\n     - Slight profit ($13 million) from some business investments, compared to a $74 million loss in 2022.\n\n2. **More \"Other Income\":**\n   - They earned an extra $241 million from other sources, mainly due to gains from reinsurance deals in early 2023.\n\n3. **Tax Benefits:**\n   - They gained $238 million in tax advantages, including a $205 million asset from Bermuda’s new corporate tax law and $25 million from better financial projections in the U.S. However, in Europe and the U.K., losses didn’t provide tax benefits.\n\nIn summary, better investment performance, new income sources, and favorable tax changes turned a big 2022 loss into a $1.1 billion profit in 2023.\n"
        }
      ],
      "execution_count": 87,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762157779
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Issue 1:** I want to keep numerical values in more readable output format."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative1= f\"\"\" Your task is to organize given information in table format by keeping numarical values. \n",
        "\n",
        "### Context:\n",
        "{text}\n",
        "###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 88,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762157956
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative1}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Here is the information organized in a table format, retaining all numerical values:\n\n| **Metric/Category**                                                                                  | **2023**     | **2022**       | **Change/Explanation**                                                                                  |\n|-----------------------------------------------------------------------------------------------------|-------------|----------------|---------------------------------------------------------------------------------------------------------|\n| **Net Income Attributable to Ordinary Shareholders**                                                | $1.1 billion| $(906) million | Improvement due to favorable investment returns and other changes detailed below.                       |\n|                                                                                                     |             |                |                                                                                                         |\n| **Total Investment Returns Recognized in Net Income**                                               | $1.1 billion| $(1.2) billion| Driven by multiple factors mentioned below.                                                            |\n| - Net Unrealized Gains (Losses) on Other Investments (including equities)                           | $397 million| $(433) million | Reflecting strong global equity market performance and tightening high-yield credit spreads in 2023.    |\n| - Net Realized and Unrealized Gains (Losses) on Fixed Maturities                                    | $66 million | $(1.2) billion | Results from a decrease in interest rates in 2023 versus significant increases in 2022.                |\n| - Net Investment Income                                                                             | $192 million| (Increase)     | Due to reinvestment at higher yields, rising interest rates, and deployment of proceeds from transactions. |\n| - Income (Losses) from Equity Method Investments                                                   | $13 million | $(74) million  | Income from Core Specialty and Citco offset by Monument Re losses, improvement compared to 2022.       |\n|                                                                                                     |             |                |                                                                                                         |\n| **Other Income**                                                                                   | (Increase)  | +$241 million  | Primarily driven by Q1 2023 net gain from novation of Enhanzed Re reinsurance.                         |\n|                                                                                                     |             |                |                                                                                                         |\n| **Favorable Change in Income Tax Benefit**                                                         | +$238 million| -              | Driven by the establishment of $205 million deferred tax asset and $25 million valuation allowance release. |\n| - Bermuda Corporate Income Tax Deferred Asset                                                      | $205 million| -              | Related to enactment of the Bermuda Corporate Income Tax in December 2023.                             |\n| - Partial Release of Deferred Tax Asset Valuation Allowance                                        | $25 million | -              | Due to increases in projected taxable income and decrease in unrealized investment losses.             |\n|                                                                                                     |             |                |                                                                                                         |\n\nLet me know if this needs further adjustments!\n"
        }
      ],
      "execution_count": 89,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762165055
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Issue 2:** It is long so I need a brief summary."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative2= f\"\"\" \n",
        "Your task is to organize given information briefly in table format by keeping numarical values.\n",
        "\n",
        "Then, provide simple explanation by using at most 20 words.\n",
        "\n",
        "### Context:\n",
        "{text}\n",
        "###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 90,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762165236
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative2}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "### Summary Table:\n\n| Metric                                  | 2023 Value ($M) | 2022 Value ($M) | Change ($M)         |\n|-----------------------------------------|-----------------|-----------------|---------------------|\n| **Net Income Attributable to Shareholders** | 1,100           | (906)           | +2,006              |\n| **Total Investment Returns**           | 1,100           | (1,200)         | +2,300              |\n| - Net Unrealized Gains (Losses)         | 397             | (433)           | +830                |\n| - Fixed Maturities Gains (Losses)       | 66              | (1,200)         | +1,266              |\n| - Net Investment Income                 | 192             | N/A             | +192                |\n| - Equity Method Investments Gain (Loss) | 13              | (74)            | +87                 |\n| **Other Income**                        | 241             | N/A             | +241                |\n| **Income Tax Benefit**                  | 238             | N/A             | +238                |\n\n---\n\n### Simple Explanation:\n2023 profit improved by $2B from investment gains, tax benefits, higher income, and favorable market conditions versus 2022 losses.\n"
        }
      ],
      "execution_count": 91,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762178742
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_iterative3= f\"\"\" Your task is to organize given information briefly in table format by keeping numarical values.\n",
        "\n",
        "Then, provide simple explanation of the given context by using at most 20 words.\n",
        "\n",
        "Format everything as HTML that can be used in a website. \n",
        "\n",
        "### Context:\n",
        "{text}\n",
        "###\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": 92,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762178910
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"You are a helpful assistant.\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\", # model = \"deployment_name\".\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": prompt_iterative3}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "```html\n<table border=\"1\">\n    <thead>\n        <tr>\n            <th>Metrics</th>\n            <th>2023</th>\n            <th>2022</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>Net income attributable to ordinary shareholders</td>\n            <td>$1.1 billion</td>\n            <td>Net loss of $906 million</td>\n        </tr>\n        <tr>\n            <td>Net unrealized gains (losses) on investments (including equities)</td>\n            <td>$397 million</td>\n            <td>Net unrealized losses of $433 million</td>\n        </tr>\n        <tr>\n            <td>Net realized and unrealized gains (losses) on fixed maturities</td>\n            <td>$66 million</td>\n            <td>Net losses of $1.2 billion</td>\n        </tr>\n        <tr>\n            <td>Net investment income</td>\n            <td>Increase of $192 million</td>\n            <td>Lower in comparison</td>\n        </tr>\n        <tr>\n            <td>Income from equity method investments</td>\n            <td>$13 million</td>\n            <td>Losses of $74 million</td>\n        </tr>\n        <tr>\n            <td>Other income</td>\n            <td>Increase of $241 million</td>\n            <td>Lower in comparison</td>\n        </tr>\n        <tr>\n            <td>Favorable change in income tax benefit</td>\n            <td>$238 million</td>\n            <td>Lower in comparison</td>\n        </tr>\n        <tr>\n            <td>Deferred tax asset establishment</td>\n            <td>$205 million</td>\n            <td>N/A</td>\n        </tr>\n    </tbody>\n</table>\n\n<p><strong>Explanation:</strong> Significant net income increase in 2023 driven by favorable investment returns, higher income, and improved tax benefits compared to 2022.</p>\n```\n"
        }
      ],
      "execution_count": 93,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762196923
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display the HTML content of the completion response"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(response.choices[0].message.content))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "```html\n<table border=\"1\">\n    <thead>\n        <tr>\n            <th>Metrics</th>\n            <th>2023</th>\n            <th>2022</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>Net income attributable to ordinary shareholders</td>\n            <td>$1.1 billion</td>\n            <td>Net loss of $906 million</td>\n        </tr>\n        <tr>\n            <td>Net unrealized gains (losses) on investments (including equities)</td>\n            <td>$397 million</td>\n            <td>Net unrealized losses of $433 million</td>\n        </tr>\n        <tr>\n            <td>Net realized and unrealized gains (losses) on fixed maturities</td>\n            <td>$66 million</td>\n            <td>Net losses of $1.2 billion</td>\n        </tr>\n        <tr>\n            <td>Net investment income</td>\n            <td>Increase of $192 million</td>\n            <td>Lower in comparison</td>\n        </tr>\n        <tr>\n            <td>Income from equity method investments</td>\n            <td>$13 million</td>\n            <td>Losses of $74 million</td>\n        </tr>\n        <tr>\n            <td>Other income</td>\n            <td>Increase of $241 million</td>\n            <td>Lower in comparison</td>\n        </tr>\n        <tr>\n            <td>Favorable change in income tax benefit</td>\n            <td>$238 million</td>\n            <td>Lower in comparison</td>\n        </tr>\n        <tr>\n            <td>Deferred tax asset establishment</td>\n            <td>$205 million</td>\n            <td>N/A</td>\n        </tr>\n    </tbody>\n</table>\n\n<p><strong>Explanation:</strong> Significant net income increase in 2023 driven by favorable investment returns, higher income, and improved tax benefits compared to 2022.</p>\n```"
          },
          "metadata": {}
        }
      ],
      "execution_count": 94,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1749762197112
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}