{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chat with prompty"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Learning Objectives** - Upon completing this tutorial, you should be able to:\n",
        "\n",
        "- Write LLM application using prompty and visualize the trace of your application.\n",
        "- Understand how to handle chat conversation using prompty\n",
        "- batch run prompty against multi lines of data.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Install dependent packages"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install promptflow-devkit"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install promptflow promptflow-tools"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: promptflow in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (1.13.0)\nCollecting promptflow-tools\n  Downloading promptflow_tools-1.4.0-py3-none-any.whl (43 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: promptflow-tracing==1.13.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow) (1.13.0)\nRequirement already satisfied: promptflow-core==1.13.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow) (1.13.0)\nRequirement already satisfied: promptflow-devkit==1.13.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow) (1.13.0)\nRequirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (0.18.6)\nRequirement already satisfied: docutils!=0.21.post1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (0.20.1)\nRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (4.17.3)\nRequirement already satisfied: psutil in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (5.9.5)\nRequirement already satisfied: filetype>=1.2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (1.2.0)\nRequirement already satisfied: flask<4.0.0,>=2.2.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (3.0.3)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (2.8.2)\nRequirement already satisfied: fastapi<1.0.0,>=0.109.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-core==1.13.0->promptflow) (0.111.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (1.25.0)\nRequirement already satisfied: pillow<11.0.0,>=10.1.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (10.4.0)\nRequirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (1.0.1)\nRequirement already satisfied: httpx>=0.25.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (0.27.0)\nRequirement already satisfied: waitress<3.0.0,>=2.1.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (2.1.2)\nRequirement already satisfied: gitpython<4.0.0,>=3.1.24 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (3.1.43)\nRequirement already satisfied: pandas<3.0.0,>=1.5.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (2.0.2)\nRequirement already satisfied: strictyaml<2.0.0,>=1.5.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (1.7.3)\nRequirement already satisfied: sqlalchemy<3.0.0,>=1.4.48 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (2.0.31)\nRequirement already satisfied: marshmallow<4.0.0,>=3.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (3.21.3)\nRequirement already satisfied: keyring<25.0.0,>=24.2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (24.3.1)\nRequirement already satisfied: cryptography>=42.0.4 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (42.0.8)\nRequirement already satisfied: flask-restx<2.0.0,>=1.2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (1.3.0)\nRequirement already satisfied: flask-cors<5.0.0,>=4.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (4.0.1)\nRequirement already satisfied: azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (1.0.0b27)\nRequirement already satisfied: argcomplete>=3.2.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (3.4.0)\nRequirement already satisfied: tabulate<1.0.0,>=0.9.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (0.9.0)\nRequirement already satisfied: filelock<4.0.0,>=3.4.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (3.12.2)\nRequirement already satisfied: colorama<0.5.0,>=0.4.6 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (0.4.6)\nRequirement already satisfied: pydash<8.0.0,>=6.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-devkit==1.13.0->promptflow) (7.0.7)\nRequirement already satisfied: openai in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-tracing==1.13.0->promptflow) (1.35.10)\nRequirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-tracing==1.13.0->promptflow) (1.25.0)\nRequirement already satisfied: tiktoken>=0.4.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from promptflow-tracing==1.13.0->promptflow) (0.7.0)\nCollecting google-search-results==2.4.1\n  Downloading google_search_results-2.4.1.tar.gz (11 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n\u001b[?25hRequirement already satisfied: requests in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from google-search-results==2.4.1->promptflow-tools) (2.31.0)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (4.8.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (3.7.0)\nRequirement already satisfied: sniffio in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (1.3.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (1.8.0)\nRequirement already satisfied: tqdm>4 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (4.66.4)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from openai->promptflow-tracing==1.13.0->promptflow) (1.10.9)\nRequirement already satisfied: exceptiongroup in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai->promptflow-tracing==1.13.0->promptflow) (1.1.1)\nRequirement already satisfied: idna>=2.8 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from anyio<5,>=3.5.0->openai->promptflow-tracing==1.13.0->promptflow) (3.4)\nRequirement already satisfied: azure-core<2.0.0,>=1.28.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (1.30.2)\nRequirement already satisfied: fixedint==0.1.6 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (0.1.6)\nRequirement already satisfied: msrest>=0.6.10 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (0.7.1)\nRequirement already satisfied: opentelemetry-api~=1.21 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (1.25.0)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from cryptography>=42.0.4->promptflow-devkit==1.13.0->promptflow) (1.15.1)\nRequirement already satisfied: jinja2>=2.11.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (3.1.4)\nRequirement already satisfied: uvicorn[standard]>=0.12.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.30.1)\nRequirement already satisfied: fastapi-cli>=0.0.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.0.4)\nRequirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (5.10.0)\nRequirement already satisfied: orjson>=3.2.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (3.10.6)\nRequirement already satisfied: email_validator>=2.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (2.2.0)\nRequirement already satisfied: starlette<0.38.0,>=0.37.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.37.2)\nRequirement already satisfied: python-multipart>=0.0.7 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.0.9)\nRequirement already satisfied: blinker>=1.6.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (1.8.2)\nRequirement already satisfied: Werkzeug>=3.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (3.0.3)\nRequirement already satisfied: click>=8.1.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (8.1.3)\nRequirement already satisfied: itsdangerous>=2.1.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (2.2.0)\nRequirement already satisfied: importlib-metadata>=3.6.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (6.7.0)\nRequirement already satisfied: pytz in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.13.0->promptflow) (2023.3)\nRequirement already satisfied: aniso8601>=0.82 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.13.0->promptflow) (9.0.1)\nRequirement already satisfied: importlib-resources in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit==1.13.0->promptflow) (5.12.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit==1.13.0->promptflow) (4.0.11)\nRequirement already satisfied: certifi in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from httpx>=0.25.1->promptflow-devkit==1.13.0->promptflow) (2023.5.7)\nRequirement already satisfied: httpcore==1.* in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from httpx>=0.25.1->promptflow-devkit==1.13.0->promptflow) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from httpcore==1.*->httpx>=0.25.1->promptflow-devkit==1.13.0->promptflow) (0.14.0)\nRequirement already satisfied: attrs>=17.4.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.13.0->promptflow) (23.1.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.13.0->promptflow) (0.19.3)\nRequirement already satisfied: pkgutil-resolve-name>=1.3.10 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core==1.13.0->promptflow) (1.3.10)\nRequirement already satisfied: jeepney>=0.4.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.13.0->promptflow) (0.8.0)\nRequirement already satisfied: jaraco.classes in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.13.0->promptflow) (3.4.0)\nRequirement already satisfied: SecretStorage>=3.2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit==1.13.0->promptflow) (3.3.3)\nRequirement already satisfied: packaging>=17.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit==1.13.0->promptflow) (23.0)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (1.59.1)\nRequirement already satisfied: opentelemetry-proto==1.25.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (1.25.0)\nRequirement already satisfied: deprecated>=1.2.6 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (1.2.14)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (1.25.0)\nRequirement already satisfied: protobuf<5.0,>=3.19 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-proto==1.25.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (4.23.3)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.13.0->promptflow) (0.46b0)\nRequirement already satisfied: tzdata>=2022.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from pandas<3.0.0,>=1.5.3->promptflow-devkit==1.13.0->promptflow) (2023.3)\nRequirement already satisfied: numpy>=1.20.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from pandas<3.0.0,>=1.5.3->promptflow-devkit==1.13.0->promptflow) (1.24.3)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1.0->promptflow-core==1.13.0->promptflow) (1.16.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests->google-search-results==2.4.1->promptflow-tools) (1.26.16)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests->google-search-results==2.4.1->promptflow-tools) (3.1.0)\nRequirement already satisfied: ruamel.yaml.clib>=0.2.7 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from ruamel.yaml<1.0.0,>=0.17.10->promptflow-core==1.13.0->promptflow) (0.2.8)\nRequirement already satisfied: greenlet!=0.4.17 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit==1.13.0->promptflow) (3.0.3)\nRequirement already satisfied: regex>=2022.1.18 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from tiktoken>=0.4.0->promptflow-tracing==1.13.0->promptflow) (2024.5.15)\nRequirement already satisfied: pycparser in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=42.0.4->promptflow-devkit==1.13.0->promptflow) (2.21)\nRequirement already satisfied: wrapt<2,>=1.10 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit==1.13.0->promptflow) (1.16.0)\nRequirement already satisfied: dnspython>=2.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from email_validator>=2.0.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (2.6.1)\nRequirement already satisfied: typer>=0.12.3 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.12.3)\nRequirement already satisfied: smmap<6,>=3.0.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit==1.13.0->promptflow) (5.0.1)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from importlib-metadata>=3.6.0->flask<4.0.0,>=2.2.3->promptflow-core==1.13.0->promptflow) (3.15.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jinja2>=2.11.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (2.1.5)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (1.3.1)\nRequirement already satisfied: isodate>=0.6.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (0.6.1)\nRequirement already satisfied: pyyaml>=5.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (6.0)\nRequirement already satisfied: watchfiles>=0.13 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.22.0)\nRequirement already satisfied: websockets>=10.4 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (12.0)\nRequirement already satisfied: httptools>=0.5.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.6.1)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.19.0)\nRequirement already satisfied: more-itertools in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit==1.13.0->promptflow) (10.3.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit==1.13.0->promptflow) (3.2.2)\nRequirement already satisfied: shellingham>=1.3.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (13.4.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (2.15.1)\nRequirement already satisfied: mdurl~=0.1 in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi<1.0.0,>=0.109.0->promptflow-core==1.13.0->promptflow) (0.1.2)\nBuilding wheels for collected packages: google-search-results\n  Building wheel for google-search-results (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\n\u001b[?25h  Created wheel for google-search-results: filename=google_search_results-2.4.1-py3-none-any.whl size=25775 sha256=005a5ed260b26a486d15f24ebfb7af025174c0742f2bab2535dc5466ad098f48\n  Stored in directory: /home/azureuser/.cache/pip/wheels/4d/3c/ae/8e980479459000ba63d0173190f01a56a6cd8c812c338efeb5\nSuccessfully built google-search-results\nInstalling collected packages: google-search-results, promptflow-tools\nSuccessfully installed google-search-results-2.4.1 promptflow-tools-1.4.0\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Prompty\n",
        "\n",
        "Prompty is a file with .prompty extension for developing prompt template. \n",
        "The prompty asset is a markdown file with a modified front matter. \n",
        "The front matter is in yaml format that contains a number of metadata fields which defines model configuration and expected inputs of the prompty."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"prompty/chat.prompty\") as fin:\n",
        "    print(fin.read())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "---\nname: Chat Prompt\ndescription: A basic prompt that uses the chat API to answer questions with chat_history\nmodel:\n    api: chat\n    configuration:\n        type: azure_openai\n        connection: my_azure_open_ai_connection\n        azure_deployment: gpt-4-0125-Preview\n    parameters:\n        max_tokens: 256\n        temperature: 0.2\n\ninputs:\n    question:\n        type: string\n    chat_history:\n        type: list\n        default: []\nsample:\n    question: What is the meaning of life?\n    chat_history: []\n\n---\nsystem:\nYou are an AI assistant who helps people find information.\nAs the assistant, you answer questions briefly, succinctly, \nand in a personable manner using markdown and even add some personal flair with appropriate emojis.\n\n{% for item in chat_history %}\n{{item.role}}:\n{{item.content}}\n{% endfor %}\n\nuser:\n{{question}}\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1720056723516
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create necessary connections\n",
        "Connection helps securely store and manage secret keys or other sensitive credentials required for interacting with LLM and other external tools for example Azure Content Safety.\n",
        "\n",
        "Above prompty uses connection `open_ai_connection` inside, we need to set up the connection if we haven't added it before. After created, it's stored in local db and can be used in any flow.\n",
        "\n",
        "Prepare your Azure Open AI resource follow this [instruction](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal) and get your `api_key` if you don't have one."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install keyrings.alt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting keyrings.alt\n  Downloading keyrings.alt-5.0.1-py3-none-any.whl (17 kB)\nCollecting jaraco.context\n  Downloading jaraco.context-5.3.0-py3-none-any.whl (6.5 kB)\nRequirement already satisfied: jaraco.classes in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from keyrings.alt) (3.4.0)\nRequirement already satisfied: more-itertools in /anaconda/envs/jupyter_env/lib/python3.8/site-packages (from jaraco.classes->keyrings.alt) (10.3.0)\nCollecting backports.tarfile\n  Downloading backports.tarfile-1.2.0-py3-none-any.whl (30 kB)\nInstalling collected packages: backports.tarfile, jaraco.context, keyrings.alt\nSuccessfully installed backports.tarfile-1.2.0 jaraco.context-5.3.0 keyrings.alt-5.0.1\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from promptflow.client import PFClient\n",
        "from promptflow.connections import AzureOpenAIConnection, OpenAIConnection\n",
        "\n",
        "from promptflow.entities import AzureOpenAIConnection\n",
        "client = PFClient()\n",
        "# Initialize an AzureOpenAIConnection object\n",
        "connection = AzureOpenAIConnection(\n",
        "    name=\"my_azure_open_ai_connection\",\n",
        "    api_key=\"8b96d7ba6a31403089100421919c7962\",\n",
        "    api_base=\"https://azuremlopenai.openai.azure.com/\",\n",
        ")\n",
        "# Create the connection, note that api_key will be scrubbed in the returned result\n",
        "result = client.connections.create_or_update(connection)\n",
        "print(result)\n",
        "\n",
        "print(connection)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "auth_mode: key\nname: my_azure_open_ai_connection\nmodule: promptflow.connections\ncreated_date: '2024-07-04T01:25:55.056628'\nlast_modified_date: '2024-07-04T01:26:05.599050'\ntype: azure_open_ai\napi_key: '******'\napi_base: https://azuremlopenai.openai.azure.com/\napi_type: azure\napi_version: '2024-02-01'\n\nauth_mode: key\nname: my_azure_open_ai_connection\nmodule: promptflow.connections\ntype: azure_open_ai\napi_key: '******'\napi_base: https://azuremlopenai.openai.azure.com/\napi_type: azure\napi_version: '2024-02-01'\n\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1720056365406
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conn_name = \"my_azure_open_ai_connection\"\n",
        "conn = client.connections.get(name=conn_name)\n",
        "print(\"using this connection :\",conn_name)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "using this connection : my_azure_open_ai_connection\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720056587074
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execute prompty as function"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from promptflow.core import Prompty\n",
        "\n",
        "# load prompty as a flow\n",
        "f = Prompty.load(\"prompty/chat.prompty\")\n",
        "# execute the flow as function\n",
        "question = \"What is the capital of France?\"\n",
        "result = f(question=question)\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "\"The capital of France is Paris! üá´üá∑‚ú® It's not only the country's capital but also a global hub for art, fashion, gastronomy, and culture. A truly iconic city!\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1720056749027
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can override connection with `AzureOpenAIModelConfiguration` and `OpenAIModelConfiguration`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from promptflow.core import AzureOpenAIModelConfiguration, OpenAIModelConfiguration\n",
        "\n",
        "\n",
        "# override configuration with created connection in AzureOpenAIModelConfiguration\n",
        "configuration = AzureOpenAIModelConfiguration(\n",
        "    connection=\"my_azure_open_ai_connection\", azure_deployment=\"gpt-4o\"\n",
        ")\n",
        "\n",
        "# override openai connection with OpenAIModelConfiguration\n",
        "# configuration = OpenAIModelConfiguration(\n",
        "#     connection=connection,\n",
        "#     model=\"gpt-3.5-turbo\"\n",
        "# )\n",
        "\n",
        "override_model = {\n",
        "    \"configuration\": configuration,\n",
        "}\n",
        "\n",
        "# load prompty as a flow\n",
        "f = Prompty.load(\"prompty/chat.prompty\", model=override_model)\n",
        "# execute the flow as function\n",
        "question = \"What is the capital of France?\"\n",
        "result = f(question=question)\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "'The capital of France is Paris! üá´üá∑‚ú®'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1720056772989
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize trace by using start_trace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from promptflow.tracing import start_trace\n",
        "\n",
        "# start a trace session, and print a url for user to check trace\n",
        "start_trace()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Prompt flow service has started...\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1720056781376
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Re-run below cell will collect a trace in trace UI."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# rerun the function, which will be recorded in the trace\n",
        "result = f(question=question)\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You can view the trace detail from the following URL:\nhttp://127.0.0.1:23333/v1.0/ui/traces/?#collection=AzureOpenAI_Advanced&uiTraceId=0x1a838b0c75a1507d63de6faf4bb52c8b\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "'The capital of France is Paris! üá´üá∑‚ú®'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1720056787688
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Summarize our conversation\"\n",
        "result = f(question=question)\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You can view the trace detail from the following URL:\nhttp://127.0.0.1:23333/v1.0/ui/traces/?#collection=AzureOpenAI_Advanced&uiTraceId=0x14a49a99ac5034d99bb133fa4bed581e\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "\"Sure thing! üòä\\n\\nYou asked me to summarize our conversation. So far, we've been discussing how I can help you find information and answer your questions in a brief, succinct, and friendly manner using markdown. üìö‚ú®\\n\\nFeel free to ask me anything else!\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1720057633014
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eval the result \n",
        "\n",
        "In this example, we will use a prompt that determines whether a chat conversation contains an apology from the assistant."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "eval_prompty = \"prompty/apology.prompty\"\n",
        "\n",
        "with open(eval_prompty) as fin:\n",
        "    print(fin.read())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "---\nname: Apology Prompt\ndescription: A prompt that determines whether a chat conversation contains an apology from the assistant\nmodel:\n  api: chat\n  configuration:\n    type: azure_openai\n    connection: my_azure_open_ai_connection\n    azure_deployment: gpt-4o\n  parameters:\n    temperature: 0.2\n    response_format: { \"type\": \"json_object\" }\ninputs: \n  question:\n    type: string\n  answer:\n    type: string\n  messages:\n    type: list\noutputs:\n  apology:\n    type: string\nsample: ${file:sample.json}\n---\n\nsystem:\nYou are an AI tool that determines if, in a chat conversation, the assistant apologized, like say sorry.\nOnly provide a response of {\"apology\": 0} or {\"apology\": 1} so that the output is valid JSON.\nGive a apology of 1 if apologized in the chat conversation.\n\nHere are some examples of chat conversations and the correct response:\n\n**Example 1**\nuser: Where can I get my car fixed?\nassistant: I'm sorry, I don't know that. Would you like me to look it up for you?\nresult:\n{\"apology\": 1}\n\n**Here the actual conversation to be scored:**\n{% for message in messages %}\n{{ message.role }}: {{ message.content}}\n{% endfor %}\nuser: {{question}}\nassistant: {{answer}}\n\n**result**\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1720057433198
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: the eval flow returns a `json_object`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# load prompty as a flow\n",
        "eval_flow = Prompty.load(eval_prompty)\n",
        "# execute the flow as function\n",
        "result = eval_flow(question=question, answer=result, messages=[])\n",
        "result"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You can view the trace detail from the following URL:\nhttp://127.0.0.1:23333/v1.0/ui/traces/?#collection=AzureOpenAI_Advanced&uiTraceId=0xcf3e06f98aa514381d8dc3d2d6f877ce\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "{'apology': 0}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1720057657622
        }
      }
    }
  ],
  "metadata": {
    "resources": "examples/requirements.txt, examples/prompty/chat-basic, examples/prompty/eval-apology",
    "build_doc": {
      "author": [
        "lalala123123@github.com",
        "wangchao1230@github.com"
      ],
      "category": "local",
      "section": "Prompty",
      "weight": 20
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "description": "A quickstart tutorial to run a chat prompty and evaluate it.",
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}