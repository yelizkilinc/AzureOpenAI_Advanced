{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Introduction\n",
        " \n",
        "The Azure AI Evaluation SDK allows you to quantitatively and qualitatively evaluate Generative AI applications both locally and at scale. It includes a variety of built-in evaluators you can use with your test data, and supports evaluation for both single-turn and multi-turn conversations, as well as multi-modal data (e.g., images). This is a very simple notebook for AI Evaluation SDK."
      ],
      "metadata": {},
      "id": "3973276c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Environment Setup\n",
        " \n",
        "Make sure you have access to the necessary Azure OpenAI resources. Set the following environment variables in your system (or in your notebook for demonstration):"
      ],
      "metadata": {},
      "id": "89eda68f"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set up Azure OpenAI\n",
        "load_dotenv(\"credentials.env\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1749743715494
        }
      },
      "id": "fa04cf80"
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. SDK Installation\n",
        " \n",
        "Install the Azure AI Evaluation SDK:"
      ],
      "metadata": {},
      "id": "fe6462d9"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azure-ai-evaluation  "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: azure-ai-evaluation in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.8.0)\nRequirement already satisfied: azure-core>=1.30.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-evaluation) (1.33.0)\nRequirement already satisfied: promptflow-core>=1.17.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-evaluation) (1.18.0)\nRequirement already satisfied: azure-storage-blob>=12.10.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-evaluation) (12.25.1)\nRequirement already satisfied: pandas<3.0.0,>=2.1.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-evaluation) (2.3.0)\nRequirement already satisfied: openai>=1.78.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-evaluation) (1.84.0)\nRequirement already satisfied: Jinja2>=3.1.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-evaluation) (3.1.6)\nRequirement already satisfied: nltk>=3.9.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-evaluation) (3.9.1)\nRequirement already satisfied: httpx>=0.25.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-evaluation) (0.28.1)\nRequirement already satisfied: azure-identity>=1.16.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-evaluation) (1.21.0)\nRequirement already satisfied: aiohttp>=3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-evaluation) (3.11.16)\nRequirement already satisfied: msrest>=0.6.21 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-evaluation) (0.7.1)\nRequirement already satisfied: promptflow-devkit>=1.17.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-evaluation) (1.18.0)\nRequirement already satisfied: pyjwt>=2.8.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-evaluation) (2.10.1)\nRequirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-ai-evaluation) (0.18.14)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (5.0.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.5.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (2.6.1)\nRequirement already satisfied: propcache>=0.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (0.3.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (25.3.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (6.4.3)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.19.0)\nRequirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (2.32.3)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (1.17.0)\nRequirement already satisfied: typing-extensions>=4.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (4.13.2)\nRequirement already satisfied: cryptography>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (45.0.3)\nRequirement already satisfied: msal>=1.30.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (1.31.2b1)\nRequirement already satisfied: msal-extensions>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-identity>=1.16.0->azure-ai-evaluation) (1.2.0)\nRequirement already satisfied: isodate>=0.6.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-storage-blob>=12.10.0->azure-ai-evaluation) (0.7.2)\nRequirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (1.0.8)\nRequirement already satisfied: anyio in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (4.9.0)\nRequirement already satisfied: certifi in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (2025.1.31)\nRequirement already satisfied: idna in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.1->azure-ai-evaluation) (0.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from Jinja2>=3.1.6->azure-ai-evaluation) (3.0.2)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msrest>=0.6.21->azure-ai-evaluation) (2.0.0)\nRequirement already satisfied: joblib in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (1.2.0)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (4.67.1)\nRequirement already satisfied: regex>=2021.8.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (2024.11.6)\nRequirement already satisfied: click in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (8.1.8)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai>=1.78.0->azure-ai-evaluation) (2.9.2)\nRequirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai>=1.78.0->azure-ai-evaluation) (1.9.0)\nRequirement already satisfied: sniffio in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai>=1.78.0->azure-ai-evaluation) (1.3.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from openai>=1.78.0->azure-ai-evaluation) (0.10.0)\nRequirement already satisfied: tzdata>=2022.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2025.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2.9.0.post0)\nRequirement already satisfied: numpy>=1.22.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (1.23.5)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2022.5)\nRequirement already satisfied: fastapi<1.0.0,>=0.109.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (0.115.12)\nRequirement already satisfied: docstring_parser in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (0.16)\nRequirement already satisfied: flask<4.0.0,>=2.2.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (3.0.3)\nRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (4.23.0)\nRequirement already satisfied: filetype>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (1.2.0)\nRequirement already satisfied: promptflow-tracing==1.18.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (1.18.0)\nRequirement already satisfied: psutil in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (7.0.0)\nRequirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-tracing==1.18.0->promptflow-core>=1.17.1->azure-ai-evaluation) (1.34.0)\nRequirement already satisfied: tiktoken>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-tracing==1.18.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.9.0)\nRequirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.1.0)\nRequirement already satisfied: filelock<4.0.0,>=3.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.18.0)\nRequirement already satisfied: colorama<0.5.0,>=0.4.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.4.6)\nRequirement already satisfied: marshmallow<4.0.0,>=3.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.26.1)\nRequirement already satisfied: tabulate<1.0.0,>=0.9.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.9.0)\nRequirement already satisfied: sqlalchemy<3.0.0,>=1.4.48 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (2.0.41)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.34.0)\nRequirement already satisfied: pydash<8.0.0,>=6.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (7.0.7)\nRequirement already satisfied: flask-cors<6.0.0,>=5.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.0.1)\nRequirement already satisfied: waitress<4.0.0,>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.0.2)\nRequirement already satisfied: strictyaml<2.0.0,>=1.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.7.3)\nRequirement already satisfied: azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.0.0b37)\nRequirement already satisfied: gitpython<4.0.0,>=3.1.24 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.1.44)\nRequirement already satisfied: keyring<25.0.0,>=24.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (24.3.1)\nRequirement already satisfied: argcomplete>=3.2.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.5.3)\nRequirement already satisfied: pillow<11.1.0,>=10.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (11.0.0)\nRequirement already satisfied: flask-restx<2.0.0,>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.3.0)\nRequirement already satisfied: ruamel.yaml.clib>=0.2.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ruamel.yaml<1.0.0,>=0.17.10->azure-ai-evaluation) (0.2.12)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from anyio->httpx>=0.25.1->azure-ai-evaluation) (1.2.2)\nRequirement already satisfied: opentelemetry-api~=1.26 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.34.0)\nRequirement already satisfied: fixedint==0.1.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.1.6)\nRequirement already satisfied: cffi>=1.14 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation) (1.17.1)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.46.1)\nRequirement already satisfied: Werkzeug>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (3.1.3)\nRequirement already satisfied: itsdangerous>=2.1.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (2.1.2)\nRequirement already satisfied: blinker>=1.6.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (1.9.0)\nRequirement already satisfied: aniso8601>=0.82 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (10.0.1)\nRequirement already satisfied: importlib-resources in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (6.4.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation) (4.0.12)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.19.1)\nRequirement already satisfied: SecretStorage>=3.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.3.3)\nRequirement already satisfied: importlib-metadata>=4.11.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (8.2.0)\nRequirement already satisfied: jeepney>=0.4.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.9.0)\nRequirement already satisfied: jaraco.classes in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.4.0)\nRequirement already satisfied: packaging>=17.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit>=1.17.1->azure-ai-evaluation) (25.0)\nRequirement already satisfied: portalocker<3,>=1.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from msal-extensions>=1.2.0->azure-identity>=1.16.0->azure-ai-evaluation) (2.10.1)\nRequirement already satisfied: opentelemetry-proto==1.34.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.34.0)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.69.2)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.34.0)\nRequirement already satisfied: protobuf<6.0,>=5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-proto==1.34.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.29.5)\nRequirement already satisfied: annotated-types>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.78.0->azure-ai-evaluation) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.78.0->azure-ai-evaluation) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (1.26.20)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-evaluation) (3.2.2)\nRequirement already satisfied: greenlet>=1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.2.1)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from cffi>=1.14->cryptography>=2.5->azure-identity>=1.16.0->azure-ai-evaluation) (2.22)\nRequirement already satisfied: smmap<6,>=3.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.0.2)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from importlib-metadata>=4.11.4->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.19.2)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.55b0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.18.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.55b0)\nRequirement already satisfied: more-itertools in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (10.7.0)\n"
        }
      ],
      "execution_count": 9,
      "metadata": {},
      "id": "fad3fb7c"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install azure-ai-projects"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: azure-ai-projects in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (1.0.0b11)\nRequirement already satisfied: isodate>=0.6.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-projects) (0.7.2)\nRequirement already satisfied: azure-core>=1.30.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-projects) (1.33.0)\nRequirement already satisfied: typing-extensions>=4.12.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-projects) (4.13.2)\nRequirement already satisfied: azure-storage-blob>=12.15.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-projects) (12.25.1)\nRequirement already satisfied: azure-ai-agents>=1.0.0b1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-projects) (1.1.0b1)\nRequirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core>=1.30.0->azure-ai-projects) (2.32.3)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core>=1.30.0->azure-ai-projects) (1.17.0)\nRequirement already satisfied: cryptography>=2.1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-storage-blob>=12.15.0->azure-ai-projects) (44.0.2)\nRequirement already satisfied: cffi>=1.12 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.15.0->azure-ai-projects) (1.17.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-projects) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-projects) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-projects) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-projects) (2025.1.31)\nRequirement already satisfied: pycparser in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.15.0->azure-ai-projects) (2.22)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1749732902113
        }
      },
      "id": "1a63d492"
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Model Configuration\n",
        " \n",
        "Required for AI-assisted evaluators (except some safety evaluators):\n",
        "You need to specify which GPT model will be used as the judge."
      ],
      "metadata": {},
      "id": "69567c7e"
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.evaluation import AzureOpenAIModelConfiguration  \n",
        "  \n",
        "model_config = AzureOpenAIModelConfiguration(  \n",
        "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],  \n",
        "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],  \n",
        "    azure_deployment=\"gpt-4o\",  \n",
        "    api_version= \"2024-02-15-preview\"  \n",
        ")  "
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1749743720082
        }
      },
      "id": "a6abef70"
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Running Built-in Evaluators (Single Row)\n",
        " \n",
        "Let's run an evaluator on a simple query-response pair using the RelevanceEvaluator:"
      ],
      "metadata": {},
      "id": "23df5c97"
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.evaluation import RelevanceEvaluator  \n",
        "  \n",
        "query = \"What is the capital of France?\"  \n",
        "response = \"Paris.\"  \n",
        "  \n",
        "relevance_eval = RelevanceEvaluator(model_config)  \n",
        "result = relevance_eval(query=query, response=response)  \n",
        "print(result)  "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'relevance': 4.0, 'gpt_relevance': 4.0, 'relevance_reason': 'The RESPONSE fully and accurately answers the QUERY, providing all necessary information without additional insights or elaboration.', 'relevance_result': 'pass', 'relevance_threshold': 3}\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1749654461254
        }
      },
      "id": "201c5eca"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supported Built-in Evaluators\n",
        "\n",
        "General purpose: CoherenceEvaluator, FluencyEvaluator, QAEvaluator, etc.\n",
        "Similarity: SimilarityEvaluator, F1ScoreEvaluator, BleuScoreEvaluator,...\n",
        "RAG: GroundednessEvaluator, RetrievalEvaluator, etc.\n",
        "Safety: ViolenceEvaluator, ContentSafetyEvaluator, ...\n",
        "See full list in Azure Docs"
      ],
      "metadata": {},
      "id": "1102faf3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Batch Evaluation with .jsonl Dataset\n",
        " \n",
        "Prepare your dataset as a .jsonl file (JSON Lines):\n",
        "\n",
        "Example: data.jsonl"
      ],
      "metadata": {},
      "id": "0f29640f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "{\"query\": \"What is the capital of France?\", \"response\": \"Paris.\"}  \n",
        "{\"query\": \"What atoms compose water?\", \"response\": \"Hydrogen and oxygen.\"}  \n",
        "{\"query\": \"What color is my shirt?\", \"response\": \"Blue.\"}  "
      ],
      "metadata": {},
      "id": "061f4757"
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now run evaluators over this dataset:"
      ],
      "metadata": {},
      "id": "255286ae"
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.evaluation import evaluate, GroundednessEvaluator  \n",
        "  \n",
        "groundedness_eval = GroundednessEvaluator(model_config)  \n",
        "  \n",
        "result = evaluate(  \n",
        "    data=\"data.jsonl\",  \n",
        "    evaluators={\"groundedness\": groundedness_eval},  \n",
        "    output_path=\"./eval_results.json\"    # Output is optional  \n",
        ")  \n",
        "import json  \n",
        "print(json.dumps(result['metrics'], indent=2))  "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[2025-06-12 14:24:10 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n[2025-06-12 14:24:10 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_groundedness_20250612_142410_422891, log path: /home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250612_142410_422891/logs.txt\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2025-06-12 14:24:10 +0000    2985 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n2025-06-12 14:24:10 +0000    2985 execution.bulk     INFO     Finished 3 / 3 lines.\n2025-06-12 14:24:10 +0000    2985 execution.bulk     INFO     Average execution time for completed lines: 0.0 seconds. Estimated time for incomplete lines: 0.0 seconds.\n2025-06-12 14:24:10 +0000    2985 execution          ERROR    3/3 flow run failed, indexes: [1,2,0], exception of index 1: (UserError) GroundednessEvaluator: Either 'conversation' or individual inputs must be provided.\n======= Run Summary =======\n\nRun name: \"azure_ai_evaluation_evaluators_groundedness_20250612_142410_422891\"\nRun status: \"Completed\"\nStart time: \"2025-06-12 14:24:10.429445+00:00\"\nDuration: \"0:00:01.077503\"\nOutput path: \"/home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250612_142410_422891\"\n\n======= Combined Run Summary (Per Evaluator) =======\n\n{\n    \"groundedness\": {\n        \"status\": \"Completed with Errors\",\n        \"duration\": \"0:00:01.077503\",\n        \"completed_lines\": 0,\n        \"failed_lines\": 3,\n        \"log_path\": \"/home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250612_142410_422891\"\n    }\n}\n\n====================================================\n\nEvaluation results saved to \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/yeliz-workshop/code/Users/admin/Azure_OpenAI_Advanced_Prompt_Engineering-/eval/eval_results.json\".\n\n{}\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1749738251478
        }
      },
      "id": "d0f74a18"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Requirements\n",
        " \n",
        "\n",
        "Each line in .jsonl must be a valid JSON object.\n",
        "Key names should match the evaluator's expected input (query, response, context, etc)."
      ],
      "metadata": {},
      "id": "846ec2b0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Evaluating Conversations\n",
        " \n",
        "Conversation Example:"
      ],
      "metadata": {},
      "id": "45b60261"
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.evaluation import GroundednessEvaluator  \n",
        "  \n",
        "conversation = {  \n",
        "    \"messages\": [  \n",
        "        {\"content\": \"Which tent is the most waterproof?\", \"role\": \"user\"},  \n",
        "        {  \n",
        "            \"content\": \"The Alpine Explorer Tent is the most waterproof\",  \n",
        "            \"role\": \"assistant\",  \n",
        "            \"context\": \"From our product list the Alpine Explorer Tent is the most waterproof.\",  \n",
        "        },  \n",
        "        {\"content\": \"How much does it cost?\", \"role\": \"user\"},  \n",
        "        {  \n",
        "            \"content\": \"The Alpine Explorer Tent is $120.\",  \n",
        "            \"role\": \"assistant\",  \n",
        "            \"context\": None,  \n",
        "        },  \n",
        "    ]  \n",
        "}  \n",
        "  \n",
        "groundedness_eval = GroundednessEvaluator(model_config)  \n",
        "score = groundedness_eval(conversation=conversation)  \n",
        "  \n",
        "import json  \n",
        "print(json.dumps(score, indent=2))  "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "ecfab128"
    },
    {
      "cell_type": "markdown",
      "source": [
        "JSONL Format for Conversations:"
      ],
      "metadata": {},
      "id": "0f7d013d"
    },
    {
      "cell_type": "code",
      "source": [
        "{\"conversation\": { \"messages\": [...] }}  "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "f45d0e9d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Using Composite Evaluators\n",
        " \n",
        "Composite evaluators group several metrics under one evaluator:\n",
        "\n",
        "QA Evaluator Example (works on query-response pairs):"
      ],
      "metadata": {},
      "id": "b58b3b78"
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_data = [\n",
        "    {\n",
        "        \"query\": \"Who invented the lightbulb?\",\n",
        "        \"response\": \"Thomas Edison invented the first commercially successful incandescent light bulb.\",\n",
        "        \"context\": \"In 1879, Thomas Edison created the first commercially successful incandescent light bulb.\"\n",
        "    },\n",
        "    # Add more entries as needed\n",
        "]\n"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {},
      "id": "aa06ed4c"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"evaluation_data.jsonl\", \"w\") as f:\n",
        "    for entry in evaluation_data:\n",
        "        f.write(json.dumps(entry) + \"\\n\")\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {},
      "id": "5eb967c8"
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.evaluation import evaluate, QAEvaluator\n",
        "\n",
        "# Initialize your evaluator\n",
        "qa_evaluator = QAEvaluator(model_config)\n",
        "\n",
        "# Run the evaluation\n",
        "result = evaluate(\n",
        "    data=\"evaluation_data.jsonl\",\n",
        "    evaluators={\"qa\": qa_evaluator},\n",
        "    evaluation_name=\"RAG Evaluation Demo\"\n",
        ")\n",
        "\n",
        "print(result[\"metrics\"])\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "c811cb0a"
    },
    {
      "cell_type": "code",
      "source": [
        "!az login"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[93mTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code AZT3388RM to authenticate.\u001b[0m\n\nRetrieving tenants and subscriptions for the selection...\n\n[Tenant and subscription selection]\n\nNo     Subscription name                  Subscription ID                       Tenant\n-----  ---------------------------------  ------------------------------------  --------\n\u001b[96m[1]\u001b[0m *  \u001b[96mME-MngEnvMCAP973053-yelizkilinc-1\u001b[0m  \u001b[96m00fd275a-dc44-46e0-81a6-ebc734ec11de\u001b[0m  \u001b[96mContoso\u001b[0m\n\nThe default is marked with an *; the default tenant is 'Contoso' and subscription is 'ME-MngEnvMCAP973053-yelizkilinc-1' (00fd275a-dc44-46e0-81a6-ebc734ec11de).\n\nSelect a subscription and tenant (Type a number or Enter for no changes): ^C\n"
        }
      ],
      "execution_count": 3,
      "metadata": {},
      "id": "3d8ee371"
    },
    {
      "cell_type": "markdown",
      "source": [
        "QA Evaluator:"
      ],
      "metadata": {},
      "id": "d5cb6088"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Groundedness Evaluator:"
      ],
      "metadata": {},
      "id": "55ba6d19"
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.evaluation import evaluate, GroundednessEvaluator\n",
        "\n",
        "# Define your Azure AI project details\n",
        "azure_ai_project = {\n",
        "    \"subscription_id\": \"XXX\",\n",
        "     \"project_name\": \"tracing\",#\"hackathon\", #\n",
        "     \"resource_group_name\": \"rg-admin-3919_ai\"#\"hackathon\" #\n",
        "}\n",
        "\n",
        "# Initialize the evaluator\n",
        "groundedness_evaluator = GroundednessEvaluator(model_config)\n",
        "\n",
        "# Run the evaluation\n",
        "result = evaluate(\n",
        "    data=\"evaluation_data.jsonl\",\n",
        "    evaluators={\"groundedness\": groundedness_evaluator},\n",
        "    evaluation_name=\"RAG Groundedness Evaluation\",\n",
        "    azure_ai_project=azure_ai_project\n",
        ")\n",
        "\n",
        "# Output the evaluation metrics and the link to Azure AI Foundry\n",
        "print(result[\"metrics\"])\n",
        "print(f\"View results in Azure AI Foundry: {result.get('studio_url')}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[2025-06-12 16:38:57 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n[2025-06-12 16:38:57 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_groundedness_20250612_163857_394168, log path: /home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250612_163857_394168/logs.txt\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2025-06-12 16:38:57 +0000    3055 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n2025-06-12 16:39:00 +0000    3055 execution.bulk     INFO     Finished 1 / 1 lines.\n2025-06-12 16:39:00 +0000    3055 execution.bulk     INFO     Average execution time for completed lines: 3.32 seconds. Estimated time for incomplete lines: 0.0 seconds.\n======= Run Summary =======\n\nRun name: \"azure_ai_evaluation_evaluators_groundedness_20250612_163857_394168\"\nRun status: \"Completed\"\nStart time: \"2025-06-12 16:38:57.401317+00:00\"\nDuration: \"0:00:04.073265\"\nOutput path: \"/home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250612_163857_394168\"\n\n======= Combined Run Summary (Per Evaluator) =======\n\n{\n    \"groundedness\": {\n        \"status\": \"Completed\",\n        \"duration\": \"0:00:04.073265\",\n        \"completed_lines\": 1,\n        \"failed_lines\": 0,\n        \"log_path\": \"/home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250612_163857_394168\"\n    }\n}\n\n====================================================\n\n{'groundedness.groundedness': 4.0, 'groundedness.gpt_groundedness': 4.0, 'groundedness.groundedness_threshold': 3.0, 'groundedness.binary_aggregate': 1.0}\nView results in Azure AI Foundry: https://ai.azure.com/build/evaluation/f7a69c17-cb20-42c5-94bc-ce904b10ce85?wsid=/subscriptions/00fd275a-dc44-46e0-81a6-ebc734ec11de/resourceGroups/rg-admin-3919_ai/providers/Microsoft.MachineLearningServices/workspaces/tracing\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1749746350967
        }
      },
      "id": "0c4108e6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Tracking Evaluations in Azure AI Project\n",
        " \n",
        "You can log evaluation runs to your Azure AI project for easier tracking:"
      ],
      "metadata": {},
      "id": "845df897"
    },
    {
      "cell_type": "code",
      "source": [
        "#example"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {},
      "id": "e349d842"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another Example:"
      ],
      "metadata": {},
      "id": "e6cff137"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install azure-ai-evaluation azure-identity\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "3072ce7b"
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.evaluation import evaluate, GroundednessEvaluator, RetrievalEvaluator, ViolenceEvaluator, BleuScoreEvaluator\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "credential = DefaultAzureCredential()\n",
        "# Define your Azure AI project details\n",
        "azure_ai_project = {\n",
        "    \"subscription_id\": \"XXX\",\n",
        "     \"project_name\": \"tracing\",#\"hackathon\", #\n",
        "     \"resource_group_name\": \"rg-admin-3919_ai\"#\"hackathon\" #\n",
        "}\n",
        "\n",
        "# Initialize evaluators\n",
        "evaluators = {\n",
        "    \"groundedness\": GroundednessEvaluator(model_config),\n",
        "    \"retrieval\": RetrievalEvaluator(model_config),\n",
        "    \"violence\": ViolenceEvaluator(credential=credential, azure_ai_project=azure_ai_project),\n",
        "    \"bleu\": BleuScoreEvaluator(threshold=0.5)\n",
        "}\n",
        "\n",
        "# Run the evaluation\n",
        "result = evaluate(\n",
        "    data=\"evaluation_data_new.jsonl\",\n",
        "    evaluators=evaluators,\n",
        "    evaluation_name=\"RAG Comprehensive Evaluation\",\n",
        "    azure_ai_project=azure_ai_project\n",
        ")\n",
        "\n",
        "# Output the evaluation metrics and the link to Azure AI Foundry\n",
        "print(result[\"metrics\"])\n",
        "print(f\"View results in Azure AI Foundry: {result.get('studio_url')}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:azure.ai.evaluation._common._experimental:Class ViolenceEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n[2025-06-12 16:39:14 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n[2025-06-12 16:39:14 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_groundedness_20250612_163914_690072, log path: /home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250612_163914_690072/logs.txt\n[2025-06-12 16:39:14 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n[2025-06-12 16:39:14 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_bleu_20250612_163914_691448, log path: /home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_bleu_20250612_163914_691448/logs.txt\n[2025-06-12 16:39:14 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n[2025-06-12 16:39:14 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_violence_20250612_163914_690926, log path: /home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_violence_20250612_163914_690926/logs.txt\n[2025-06-12 16:39:14 +0000][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n[2025-06-12 16:39:14 +0000][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_retrieval_20250612_163914_690432, log path: /home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_retrieval_20250612_163914_690432/logs.txt\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data] Downloading package perluniprops to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Unzipping misc/perluniprops.zip.\n[nltk_data] Downloading package punkt to /home/azureuser/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package punkt_tab to\n[nltk_data]     /home/azureuser/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2025-06-12 16:39:14 +0000    3055 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n2025-06-12 16:39:15 +0000    3055 execution.bulk     INFO     Finished 2 / 2 lines.\n2025-06-12 16:39:15 +0000    3055 execution.bulk     INFO     Average execution time for completed lines: 0.36 seconds. Estimated time for incomplete lines: 0.0 seconds.\n======= Run Summary =======\n\nRun name: \"azure_ai_evaluation_evaluators_bleu_20250612_163914_691448\"\nRun status: \"Completed\"\nStart time: \"2025-06-12 16:39:14.708369+00:00\"\nDuration: \"0:00:01.193616\"\nOutput path: \"/home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_bleu_20250612_163914_691448\"\n\n2025-06-12 16:39:17 +0000    3055 execution.bulk     INFO     Finished 1 / 2 lines.\n2025-06-12 16:39:17 +0000    3055 execution.bulk     INFO     Average execution time for completed lines: 2.69 seconds. Estimated time for incomplete lines: 2.69 seconds.\n2025-06-12 16:39:17 +0000    3055 execution.bulk     INFO     Finished 2 / 2 lines.\n2025-06-12 16:39:17 +0000    3055 execution.bulk     INFO     Average execution time for completed lines: 1.52 seconds. Estimated time for incomplete lines: 0.0 seconds.\n2025-06-12 16:39:14 +0000    3055 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n2025-06-12 16:39:17 +0000    3055 execution.bulk     INFO     Finished 1 / 2 lines.\n2025-06-12 16:39:17 +0000    3055 execution.bulk     INFO     Average execution time for completed lines: 2.69 seconds. Estimated time for incomplete lines: 2.69 seconds.\n2025-06-12 16:39:17 +0000    3055 execution.bulk     INFO     Finished 2 / 2 lines.\n2025-06-12 16:39:17 +0000    3055 execution.bulk     INFO     Average execution time for completed lines: 1.52 seconds. Estimated time for incomplete lines: 0.0 seconds.\n======= Run Summary =======\n\nRun name: \"azure_ai_evaluation_evaluators_groundedness_20250612_163914_690072\"\nRun status: \"Completed\"\nStart time: \"2025-06-12 16:39:14.699380+00:00\"\nDuration: \"0:00:04.143866\"\nOutput path: \"/home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250612_163914_690072\"\n\n2025-06-12 16:39:21 +0000    3055 execution.bulk     INFO     Finished 1 / 2 lines.\n2025-06-12 16:39:21 +0000    3055 execution.bulk     INFO     Average execution time for completed lines: 6.43 seconds. Estimated time for incomplete lines: 6.43 seconds.\n2025-06-12 16:39:21 +0000    3055 execution.bulk     INFO     Finished 2 / 2 lines.\n2025-06-12 16:39:21 +0000    3055 execution.bulk     INFO     Average execution time for completed lines: 3.4 seconds. Estimated time for incomplete lines: 0.0 seconds.\n2025-06-12 16:39:14 +0000    3055 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n2025-06-12 16:39:21 +0000    3055 execution.bulk     INFO     Finished 1 / 2 lines.\n2025-06-12 16:39:21 +0000    3055 execution.bulk     INFO     Average execution time for completed lines: 6.43 seconds. Estimated time for incomplete lines: 6.43 seconds.\n2025-06-12 16:39:21 +0000    3055 execution.bulk     INFO     Finished 2 / 2 lines.\n2025-06-12 16:39:21 +0000    3055 execution.bulk     INFO     Average execution time for completed lines: 3.4 seconds. Estimated time for incomplete lines: 0.0 seconds.\n======= Run Summary =======\n\nRun name: \"azure_ai_evaluation_evaluators_retrieval_20250612_163914_690432\"\nRun status: \"Completed\"\nStart time: \"2025-06-12 16:39:14.702123+00:00\"\nDuration: \"0:00:07.237636\"\nOutput path: \"/home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_retrieval_20250612_163914_690432\"\n\n2025-06-12 16:39:25 +0000    3055 execution.bulk     INFO     Finished 1 / 2 lines.\n2025-06-12 16:39:25 +0000    3055 execution.bulk     INFO     Average execution time for completed lines: 10.59 seconds. Estimated time for incomplete lines: 10.59 seconds.\n2025-06-12 16:39:25 +0000    3055 execution.bulk     INFO     Finished 2 / 2 lines.\n2025-06-12 16:39:25 +0000    3055 execution.bulk     INFO     Average execution time for completed lines: 5.54 seconds. Estimated time for incomplete lines: 0.0 seconds.\n2025-06-12 16:39:14 +0000    3055 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n2025-06-12 16:39:25 +0000    3055 execution.bulk     INFO     Finished 1 / 2 lines.\n2025-06-12 16:39:25 +0000    3055 execution.bulk     INFO     Average execution time for completed lines: 10.59 seconds. Estimated time for incomplete lines: 10.59 seconds.\n2025-06-12 16:39:25 +0000    3055 execution.bulk     INFO     Finished 2 / 2 lines.\n2025-06-12 16:39:25 +0000    3055 execution.bulk     INFO     Average execution time for completed lines: 5.54 seconds. Estimated time for incomplete lines: 0.0 seconds.\n======= Run Summary =======\n\nRun name: \"azure_ai_evaluation_evaluators_violence_20250612_163914_690926\"\nRun status: \"Completed\"\nStart time: \"2025-06-12 16:39:14.705878+00:00\"\nDuration: \"0:00:12.228135\"\nOutput path: \"/home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_violence_20250612_163914_690926\"\n\n======= Combined Run Summary (Per Evaluator) =======\n\n{\n    \"groundedness\": {\n        \"status\": \"Completed\",\n        \"duration\": \"0:00:04.143866\",\n        \"completed_lines\": 2,\n        \"failed_lines\": 0,\n        \"log_path\": \"/home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250612_163914_690072\"\n    },\n    \"retrieval\": {\n        \"status\": \"Completed\",\n        \"duration\": \"0:00:07.237636\",\n        \"completed_lines\": 2,\n        \"failed_lines\": 0,\n        \"log_path\": \"/home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_retrieval_20250612_163914_690432\"\n    },\n    \"violence\": {\n        \"status\": \"Completed\",\n        \"duration\": \"0:00:12.228135\",\n        \"completed_lines\": 2,\n        \"failed_lines\": 0,\n        \"log_path\": \"/home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_violence_20250612_163914_690926\"\n    },\n    \"bleu\": {\n        \"status\": \"Completed\",\n        \"duration\": \"0:00:01.193616\",\n        \"completed_lines\": 2,\n        \"failed_lines\": 0,\n        \"log_path\": \"/home/azureuser/.promptflow/.runs/azure_ai_evaluation_evaluators_bleu_20250612_163914_691448\"\n    }\n}\n\n====================================================\n\n{'groundedness.groundedness': 4.0, 'groundedness.gpt_groundedness': 4.0, 'groundedness.groundedness_threshold': 3.0, 'retrieval.retrieval': 3.0, 'retrieval.gpt_retrieval': 3.0, 'retrieval.retrieval_threshold': 3.0, 'violence.violence_threshold': 3.0, 'bleu.bleu_score': 0.1396620514, 'bleu.bleu_threshold': 0.5, 'violence.violence_defect_rate': 0.0, 'groundedness.binary_aggregate': 1.0, 'retrieval.binary_aggregate': 0.5, 'violence.binary_aggregate': 1.0, 'bleu.binary_aggregate': 0.0}\nView results in Azure AI Foundry: https://ai.azure.com/build/evaluation/33a84ee8-3b9a-4f34-8e4b-f761e7cb6725?wsid=/subscriptions/00fd275a-dc44-46e0-81a6-ebc734ec11de/resourceGroups/rg-admin-3919_ai/providers/Microsoft.MachineLearningServices/workspaces/tracing\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1749746385743
        }
      },
      "id": "ebdff02a"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "3c9b5085-2fe5-4c97-b44b-0503c02be885"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}